{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.random.seed(1234)\n",
    "from numpy import array,zeros,multiply,tanh,exp\n",
    "import pickle\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('train_x.pkl', 'rb') as f:\n",
    "    xtrain = pickle.load(f)\n",
    "with open('train_y.pkl', 'rb') as f:\n",
    "    ytrain = pickle.load(f)\n",
    "with open('valid_x.pkl', 'rb') as f:\n",
    "    xvalid = pickle.load(f)\n",
    "with open('valid_y.pkl', 'rb') as f:\n",
    "    yvalid = pickle.load(f)\n",
    "with open('test_x.pkl', 'rb') as f:\n",
    "    xtest = pickle.load(f)\n",
    "with open('test_y.pkl', 'rb') as f:\n",
    "    ytest = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = xtrain/255.0\n",
    "xvalid = xvalid/255.0\n",
    "xtest = xtest/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Designing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mini_batch(X,Y,batch_size = 25):\n",
    "    batch_size,num = 25,X.shape[0] / batch_size\n",
    "    return zip(np.array_split(X, num, axis=0),np.array_split(Y, num, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sig(x): \n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def tanh(x):\n",
    "    return np.tanh(x) \n",
    "def tanh_prime(x):\n",
    "    return 1.0 - x**2.0 \n",
    "def sig_prime(x): \n",
    "    return np.multiply(x, (1 - x))\n",
    "def softmax(x): \n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sigmoid():\n",
    "    def output(self, X):\n",
    "        return sig(X)\n",
    "    def input_grad(self, X, output_prime):\n",
    "        return np.multiply(sig_prime(X), output_prime)\n",
    "    def par_grad(self, X, output_grad):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tanh():\n",
    "    def output(self, X):\n",
    "        return tanh(X)\n",
    "    def input_grad(self, X, output_prime):\n",
    "        return np.multiply(tanh_prime(X), output_prime)\n",
    "    def par_grad(self, X, output_grad):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Softmax_Cost_Layer():\n",
    "    def cost(self, pred, target):\n",
    "        temp = -( target * np.log(pred)).sum()\n",
    "        return temp / pred.shape[0]\n",
    "    def input_grad(self, pred, target):\n",
    "        return (pred - target) / pred.shape[0]\n",
    "    def output(self, X):\n",
    "        return softmax(X)\n",
    "    def par_grad(self, X, output_grad):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear():\n",
    "    def __init__(self, inp, out):\n",
    "        self.W, self.B = np.random.randn(inp, out) * 0.2, zeros(out)\n",
    "        #momentum\n",
    "        self.vw,self.vb = np.zeros_like(self.W),np.zeros_like(self.B)\n",
    "        \n",
    "    def input_grad(self,inp ,output_prime):\n",
    "        return output_prime.dot(self.W.T)\n",
    "    def par_grad(self, inp, out):\n",
    "        return np.concatenate((inp.T.dot(out).flatten(),np.sum(out, axis=0).flatten()),axis = 0).tolist() \n",
    "    def output(self, inp):\n",
    "        return inp.dot(self.W) + self.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(layer_arch,activation='sig'):\n",
    "    layer_stack = []\n",
    "    layer_stack.append(Linear(xtrain.shape[1],layer_arch[0]))\n",
    "    layer_stack.append(Sigmoid())\n",
    "    for i in range(len(layer_arch)-1):\n",
    "        layer_stack.append(Linear(layer_arch[i],layer_arch[i+1]))\n",
    "        layer_stack.append(Sigmoid())\n",
    "    layer_stack.append(Linear(layer_arch[-1],ytrain.shape[1]))\n",
    "    layer_stack.append(Softmax_Cost_Layer())\n",
    "    return layer_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(inp,NN):\n",
    "    hidden_stack = [inp]\n",
    "    temp = hidden_stack[0]\n",
    "    for h_layer in NN:\n",
    "        temp = h_layer.output(temp)\n",
    "        hidden_stack.append(temp)\n",
    "    return hidden_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward(hidden_stack,T,NN):\n",
    "    temp = None\n",
    "    grad_que = deque()\n",
    "    for h_layer in reversed(NN):\n",
    "        if temp is not None:\n",
    "            temp1 = h_layer.input_grad(hidden_stack.pop(),temp)\n",
    "        else:\n",
    "            temp1 = h_layer.input_grad(hidden_stack.pop(),T)\n",
    "        grad_que.appendleft(h_layer.par_grad(hidden_stack[-1],temp))\n",
    "        temp = temp1\n",
    "    return list(grad_que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_SG(NN,grad_NN,alpha):\n",
    "    for idx in range(len(grad_NN)):\n",
    "        if len(grad_NN[idx]) > 0:\n",
    "            b_len = NN[idx].B.shape[0]\n",
    "            NN[idx].B -= alpha * array(grad_NN[idx][-b_len:])\n",
    "            NN[idx].W -= alpha * array(grad_NN[idx][:-b_len]).reshape((NN[idx].W.shape[0],NN[idx].W.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_Momentum(NN,grad_NN,alpha=0.1,mu=0.83):\n",
    "    for idx in range(len(grad_NN)):\n",
    "        if len(grad_NN[idx]) > 0:\n",
    "            b_len = NN[idx].B.shape[0]\n",
    "            beta = - alpha * array(grad_NN[idx][-b_len:])\n",
    "            gamma = - alpha * array(grad_NN[idx][:-b_len]).reshape((NN[idx].W.shape[0],NN[idx].W.shape[1]))\n",
    "            NN[idx].vb = mu * NN[idx].vb + beta\n",
    "            NN[idx].vw = mu * NN[idx].vw + gamma\n",
    "            NN[idx].B += NN[idx].vb\n",
    "            NN[idx].W += NN[idx].vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_NAG(NN,grad_NN,alpha=0.1,mu=0.83):\n",
    "    for idx in range(len(grad_NN)):\n",
    "        if len(grad_NN[idx]) > 0:\n",
    "            b_len = NN[idx].B.shape[0]\n",
    "            beta = - alpha * array(grad_NN[idx][-b_len:])\n",
    "            gamma = - alpha * array(grad_NN[idx][:-b_len]).reshape((NN[idx].W.shape[0],NN[idx].W.shape[1]))\n",
    "#             v_prev = v            \n",
    "            v_prevb = NN[idx].vb\n",
    "            v_prevw = NN[idx].vw\n",
    "#             v = mu * v - learning_rate * dx\n",
    "            NN[idx].vb = mu * NN[idx].vb + beta\n",
    "            NN[idx].vw = mu * NN[idx].vw + gamma\n",
    "#             x += -mu * v_prev + (1 + mu) * v\n",
    "            NN[idx].B += -mu * v_prevb + (1 + mu) * NN[idx].vb\n",
    "            NN[idx].W += -mu * v_prevw + (1 + mu) * NN[idx].vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_ADAM(self,dx,alpha,t,eps=1e-8,beta1=0.9,beta2=0.999):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def anneal_alpha(self):\n",
    "        self.alpha = self.alpha/2\n",
    "\n",
    "def error(x,y):\n",
    "        err = 0\n",
    "        for i in range(x.shape[0]):\n",
    "            if (np.argmax(x[i]) == np.argmax(y[i])):\n",
    "                 err+=1.0\n",
    "        return err/x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance_measure(xtrain,ytrain,xvalid,yvalid,NN,epochs=20,alpha=0.1,btch=25):\n",
    "    train_cost,valid_cost,train_acc,valid_acc = [],[],[],[]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(epoch)\n",
    "        batches = mini_batch(xtrain,ytrain)\n",
    "        for mini_x,mini_y in batches:\n",
    "            pred = forward(mini_x,NN)\n",
    "            back_grad = backward(pred,mini_y,NN)\n",
    "            update_NAG(NN,back_grad)\n",
    "        #Training loss and cost\n",
    "        pred = forward(xtrain,NN)\n",
    "        train_acc.append(error(pred[-1],ytrain))\n",
    "        train_cost.append(NN[-1].cost(pred[-1],ytrain))\n",
    "        #Validation loss and cost\n",
    "        pred = forward(xvalid,NN)\n",
    "        temp = error(pred[-1],yvalid)\n",
    "#         if temp < valid_loss[-1]:\n",
    "#             anneal_alpha()\n",
    "        valid_acc.append(temp)\n",
    "        valid_cost.append(NN[-1].cost(pred[-1],yvalid))\n",
    "    \n",
    "    return train_cost,valid_cost,train_acc,valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "model = create_model([30,30])\n",
    "t_cost,v_cost,t_acc,v_acc = performance_measure(xtrain,ytrain,xvalid,yvalid,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25179446434529362,\n",
       " 0.18625151001367715,\n",
       " 0.14991622277573907,\n",
       " 0.12779668998045157,\n",
       " 0.11441389050316539,\n",
       " 0.1007319329884636,\n",
       " 0.092612594032525489,\n",
       " 0.084695543104319454,\n",
       " 0.081162898617131399,\n",
       " 0.07715309312604704,\n",
       " 0.07272205239208876,\n",
       " 0.072481110789210254,\n",
       " 0.070957417856538779,\n",
       " 0.067502639952847263,\n",
       " 0.067974231773120494,\n",
       " 0.06180963862838218,\n",
       " 0.063353672398673219,\n",
       " 0.060632121742573944,\n",
       " 0.059215709537530727,\n",
       " 0.054993350424434553]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.92224,\n",
       " 0.94154,\n",
       " 0.9523,\n",
       " 0.95946,\n",
       " 0.96358,\n",
       " 0.96778,\n",
       " 0.97022,\n",
       " 0.97286,\n",
       " 0.97422,\n",
       " 0.97492,\n",
       " 0.97602,\n",
       " 0.97622,\n",
       " 0.97684,\n",
       " 0.97782,\n",
       " 0.97834,\n",
       " 0.98052,\n",
       " 0.97972,\n",
       " 0.98068,\n",
       " 0.98138,\n",
       " 0.98264]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.24213008015754084,\n",
       " 0.1953865336930963,\n",
       " 0.17010793973601546,\n",
       " 0.15901174880559998,\n",
       " 0.15581319302998101,\n",
       " 0.1496955278258581,\n",
       " 0.14763452670968019,\n",
       " 0.14598762198507972,\n",
       " 0.14732195767827111,\n",
       " 0.14837414679954711,\n",
       " 0.14979326481114397,\n",
       " 0.15508279073015457,\n",
       " 0.15721855507292981,\n",
       " 0.15794999628555878,\n",
       " 0.16325783206863473,\n",
       " 0.16017737764661713,\n",
       " 0.16762350143981597,\n",
       " 0.16615121409618838,\n",
       " 0.16997730438480385,\n",
       " 0.1671816429418983]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9297,\n",
       " 0.9426,\n",
       " 0.9514,\n",
       " 0.9546,\n",
       " 0.9549,\n",
       " 0.9585,\n",
       " 0.9596,\n",
       " 0.9611,\n",
       " 0.9601,\n",
       " 0.9601,\n",
       " 0.9605,\n",
       " 0.9594,\n",
       " 0.9589,\n",
       " 0.9583,\n",
       " 0.9591,\n",
       " 0.9591,\n",
       " 0.9589,\n",
       " 0.9589,\n",
       " 0.9581,\n",
       " 0.9593]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_performance_measure(xtest,ytest,NN):\n",
    "    test_acc, test_cost = [],[]\n",
    "    pred1 = forward(xtest,NN)\n",
    "    test_acc.append(error(pred1[-1],ytest))\n",
    "    test_cost.append(NN[-1].cost(pred1[-1],ytest))\n",
    "    return test_acc,test_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc,test_cost = test_performance_measure(xtest,ytest,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15921880852907819]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9602]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = genfromtxt('mnist_train.csv', delimiter=',')\n",
    "# test_data = genfromtxt('mnist_test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train = data[:50000]\n",
    "# valid = data[50000:]\n",
    "# train_y = train[:,0]\n",
    "# train_x = train[:,1:]\n",
    "# train_y_1 = np.eye(10)[train_y.astype(int)]\n",
    "# valid_y = valid[:,0]\n",
    "# valid_x = valid[:,1:]\n",
    "# valid_y_1 = np.eye(10)[valid_y.astype(int)]\n",
    "# test_y = test_data[:,0]\n",
    "# test_x = test_data[:,1:]\n",
    "# test_y_1 = np.eye(10)[test_y.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle.dump(train_x,open(\"train_x.pkl\",'wb'))\n",
    "# pickle.dump(train_y_1,open(\"train_y.pkl\",'wb'))\n",
    "# pickle.dump(valid_x,open(\"valid_x.pkl\",'wb'))\n",
    "# pickle.dump(valid_y_1,open(\"valid_y.pkl\",'wb'))\n",
    "# pickle.dump(test_x,open(\"test_x.pkl\",'wb'))\n",
    "# pickle.dump(test_y_1,open(\"test_y.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
