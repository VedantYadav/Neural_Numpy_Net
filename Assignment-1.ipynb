{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import array,zeros,dot\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = genfromtxt('mnist_train.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, inp_unit, out_unit,  hidden_shape, activation, cost, w_upd,itr=1000, alpha=0.01, momentum=0.9, decay=0.1):\n",
    "        self.inp_unit,self.out_unit,self.hidden_shape,self.itr,self.alpha,self.momentum,self.decay,self.activation = inp_unit,\\\n",
    "                                                            out_unit, hidden_shape, itr, alpha, momentum, decay, activation \n",
    "        self.cost,self.w_upd = cost,w_upd\n",
    "        self.flag,self.W,self.B,self.arc_dim = True,0,0,0     \n",
    "        self.pred,self.h_layer,self.h_layer_A,self.temp,self.Frist_time,self._v,self._m = 0,0,0,0,0,0,0\n",
    "        self.testing = []\n",
    "    \n",
    "    def initz(self,inp_unit,out_unit):\n",
    "        self.W,self.B,self.arc_dim = 0,0,0\n",
    "        self.pred,self.temp,self.Frist_time,self._v,self._m = 0,0,True,zeros((len(self.hidden_shape)+1))\\\n",
    "                                                                            ,zeros((len(self.hidden_shape)+1))\n",
    "        if len(inp_unit.shape) > 1 and len(out_unit.shape) > 1:\n",
    "            self.W,self.B,self.arc_dim = [],[],[inp_unit.shape[1]] + self.hidden_shape + [out_unit.shape[1]]\n",
    "        else:\n",
    "            self.flag = False\n",
    "    \n",
    "    def anneal_alpha(self):\n",
    "        self.alpha = self.alpha/2\n",
    "    \n",
    "    def sigmoid(self,x,flag):\n",
    "        x[x < -100] = -100\n",
    "        return 1 / (1.0 + np.exp(-x)) if flag == 0 else np.exp(-x)/((1+np.exp(-x))**2)\n",
    "\n",
    "    def tanh(self,x,flag):\n",
    "        x[x < -100] = -100\n",
    "        return np.tanh(x) if flag == 0 else 1.0 - np.tanh(x)**2.0 \n",
    "\n",
    "    def random_weight(self,shp):\n",
    "        return np.random.normal(loc = 0, scale = 0.3, size = shp)\n",
    "        \n",
    "    def _feed_forward(self,A):\n",
    "        self.h_layer,self.h_layer_A = [],[]\n",
    "        if self.Frist_time is True:\n",
    "            for idx in range(len(self.arc_dim)-1):\n",
    "                self.W.append(self.random_weight([self.arc_dim[idx],self.arc_dim[idx+1]]))\n",
    "                self.B.append(self.random_weight([1,self.arc_dim[idx+1]]))\n",
    "            self.Frist_time = False\n",
    "        for idx in range(len(self.arc_dim)-2):\n",
    "            if self.activation[idx] is \"sigmoid\":\n",
    "                A = dot(A,self.W[idx]) + self.B[idx]\n",
    "                self.h_layer.append(A)\n",
    "                C = self.sigmoid(A,0)\n",
    "                self.h_layer_A.append(C)\n",
    "            else:\n",
    "                A = dot(A,self.W[idx]) + self.B[idx]\n",
    "                self.h_layer.append(A)\n",
    "                C = self.tanh(A,0)\n",
    "                self.h_layer_A.append(C)\n",
    "        \n",
    "        if self.activation[-1] is \"sigmoid\":\n",
    "            self.temp = dot(C,self.W[idx+1]) + self.B[idx+1]\n",
    "            self.pred = self.sigmoid(self.temp,0) \n",
    "        else:\n",
    "            self.temp = dot(C,self.W[idx+1]) + self.B[idx+1]\n",
    "            self.pred = self.tanh(self.temp,0)\n",
    "    \n",
    "    def cost_func(self,targets,predct,flg=0):\n",
    "        if flg is 0:\n",
    "            return(0.5*np.sum((self.out_unit-self.pred)**2))\n",
    "        else:\n",
    "            return -1*np.sum(self.out_unit*np.log(self.pred) + (1 - self.out_unit)*np.log(self.pred))\n",
    "        \n",
    "    def _back_prop(self,Inp):\n",
    "        weight_delta = []\n",
    "        if self.cost is \"sqr\":\n",
    "            if self.activation[-1] == \"sigmoid\":\n",
    "                delta = np.multiply(-(self.out_unit-self.pred), self.sigmoid(self.temp,1))\n",
    "            else:\n",
    "                delta = np.multiply(-(self.out_unit-self.pred), self.tanh(self.temp,1))\n",
    "        else:                                                                                        # cross\n",
    "            if self.activation[-1] == \"sigmoid\":\n",
    "                delta = np.multiply(-(self.out_unit-self.pred)/(self.pred*(1-self.pred)), self.sigmoid(self.temp,1))\n",
    "            else:\n",
    "                delta = np.multiply(-(self.out_unit-self.pred)/(self.pred*(1-self.pred)), self.tanh(self.temp,1))\n",
    "        weight_delta.append(np.dot(self.h_layer_A[-1].T, delta))\n",
    "        for idx in reversed(range(len(self.h_layer))):\n",
    "            if self.activation[idx] == \"sigmoid\":\n",
    "                delta2 = np.dot(delta, self.W[idx+1].T)*self.sigmoid(self.h_layer[idx],1)\n",
    "            else:\n",
    "                delta2 = np.dot(delta, self.W[idx+1].T)*self.tanh(self.h_layer[idx],1)\n",
    "            if idx > 0:\n",
    "                weight_delta.append(np.dot(self.h_layer_A[idx-1].T, delta2))\n",
    "            else:\n",
    "                weight_delta.append(np.dot(Inp.T, delta2))\n",
    "            delta = delta2        \n",
    "        weight_delta.reverse()\n",
    "        return weight_delta\n",
    "    \n",
    "    def _weight_update_SG(self,dx,alpha):\n",
    "        for i in range(len(dx)):\n",
    "            self.W[i] += alpha * dx[i]\n",
    "    \n",
    "    def _weight_update_Momentum(self,dx,alpha,mu):\n",
    "        for i in range(len(dx)):\n",
    "            self._v[i] = mu * self._v[i] - alpha * dx[i]\n",
    "            self.W[i] += self._v[i]\n",
    "            \n",
    "    def _weight_update_Nag(self,dx,alpha,mu):\n",
    "        for i in range(len(dx)):\n",
    "            v_prev = self._v[i]\n",
    "            self._v[i] = mu * self._v[i] - alpha * dx[i]\n",
    "            self.W[i] += -mu * v_prev + (1 + mu) * self._v[i]\n",
    "            \n",
    "    def _weight_update_Adam(self,dx,alpha,t,eps=1e-8,beta1=0.9,beta2=0.999):\n",
    "        for i in range(len(dx)):\n",
    "            self._m[i] = beta1*self._m[i] + (1-beta1)*dx[i]\n",
    "            mt = self._m[i] / (1-beta1**t)\n",
    "            self._v[i] = beta2*self._v[i] + (1-beta2)*(dx[i]**2)\n",
    "            vt = self._v[i] / (1-beta2**t)\n",
    "            self.W[i] += - alpha * mt / (np.sqrt(vt) + eps)\n",
    "    \n",
    "    def mini_batch(self,batch_size = 25):\n",
    "        batch_size,num = 25,self.inp_unit.shape[0] / batch_size\n",
    "        return zip(np.array_split(self.inp_unit, num, axis=0),np.array_split(self.out_unit, num, axis=0))\n",
    "    \n",
    "    def error(self,x,y):\n",
    "        err = 0\n",
    "        for i in range(x.shape[0]):\n",
    "            if (np.argmax(x[i]) == np.argmax(y[i])):\n",
    "                 err+=1.0\n",
    "        return err/x.shape[0]\n",
    "    \n",
    "    def train(self,num_itr=100,v_x,v_y,batch_sz):\n",
    "        self.initz(self.inp_unit,self.out_unit)\n",
    "        batch = self.mini_batch(batch_sz)\n",
    "        err,loss = [],[]\n",
    "        v_err,v_loss = [],[]\n",
    "        for itr in range(num_epoch):\n",
    "            step = 0\n",
    "            for X, Y in batch:\n",
    "                self._feed_forward(X)\n",
    "                dw = self._back_prop(X)\n",
    "                if self.w_upd is 'sg':\n",
    "                    self._weight_update_SG(dw,self.alpha)\n",
    "                elif self.w_upd is 'mu':\n",
    "                    self._weight_update_Momentum(dw,self.alpha,self.momentum)\n",
    "                elif self.w_upd is 'nag':\n",
    "                    self._weight_update_Nag(dw,self.alpha,self.momentum)\n",
    "                else:\n",
    "                    self._weight_update_Adam(dw,self.alpha,itr)\n",
    "                step += 1\n",
    "                if step%100 == 0:\n",
    "                    loss.append(self.cost_func(X,Y))\n",
    "                    err.append(self.error(X,Y))\n",
    "                    self._feed_forward(v_x)\n",
    "                    loss.append(self.cost_func(v_x,v_y))\n",
    "                    err.append(self.error(v_x,v_y))\n",
    "        return err,loss,v_err,v_loss\n",
    "            \n",
    "#         for i in range(1):\n",
    "#             self._feed_forward(self.inp_unit)\n",
    "#             dx = self._back_prop(self.inp_unit)\n",
    "#             self._weight_update_SG(dx,self.alpha)\n",
    "#             if(i%10 == 0):\n",
    "#                 print(self.cost_func(self.out_unit,self.pred,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# nn = NN(train_x,train_y_1,[10,15,20],['tanh','sigmoid','tanh','sigmoid'],'sqr','sg')\n",
    "# nn.train(1000,valid_x,valid_y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.72007597602e-44\n"
     ]
    }
   ],
   "source": [
    "# a = -300\n",
    "# print((np.exp(-a)/((1+np.exp(-a))**2)))\n",
    "a = -100\n",
    "print((np.exp(-a)/((1+np.exp(-a))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 -1022\n"
     ]
    }
   ],
   "source": [
    "# np.finfo(a.dtype)\n",
    "print(np.finfo(a).maxexp,np.finfo(a).minexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = array([[1,2,3,4,5,6],[1,2,3,4,6,5]])\n",
    "np.sum(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "a = array([1,2,3,45,6,7,8])\n",
    "b = array([0,0,0,1,0,0,0])\n",
    "print(np.argmax(a) == np.argmax(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'hello'\n",
    "a is 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = data[:50000]\n",
    "valid = data[50000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[:,0]\n",
    "train_x = train[:,1:]\n",
    "train_y_1 = np.eye(10)[train_y.astype(int)]\n",
    "valid_y = valid[:,0]\n",
    "valid_x = valid[:,1:]\n",
    "valid_y_1 = np.eye(10)[valid_y.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(train_x,open(\"train_x.pkl\",'wb'))\n",
    "pickle.dump(train_y_1,open(\"train_y.pkl\",'wb'))\n",
    "pickle.dump(valid_x,open(\"valid_x.pkl\",'wb'))\n",
    "pickle.dump(valid_y_1,open(\"valid_y.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 5])\n",
    "y = tf.placeholder(tf.float32, [None, 2])\n",
    "w1 = tf.placeholder(tf.float32, [5, 3])\n",
    "w2 = tf.placeholder(tf.float32, [3, 4])\n",
    "w3 = tf.placeholder(tf.float32, [4, 5])\n",
    "w4 = tf.placeholder(tf.float32, [5, 2])\n",
    "b1 = tf.placeholder(tf.float32, [1, 3])\n",
    "b2 = tf.placeholder(tf.float32, [1, 4])\n",
    "b3 = tf.placeholder(tf.float32, [1, 5])\n",
    "b4 = tf.placeholder(tf.float32, [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Tanh_17:0\", shape=(?, 3), dtype=float32)\n",
      "Tensor(\"Sigmoid_9:0\", shape=(?, 4), dtype=float32)\n",
      "Tensor(\"Tanh_18:0\", shape=(?, 5), dtype=float32)\n",
      "Tensor(\"Add_35:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "g1 = tf.tanh(tf.add(tf.matmul(x, w1), b1))\n",
    "print(g1)\n",
    "g2 = tf.sigmoid(tf.add(tf.matmul(g1, w2), b2))\n",
    "print(g2)\n",
    "g3 = tf.tanh(tf.add(tf.matmul(g2, w3), b3))\n",
    "print(g3)\n",
    "g4 = (tf.add(tf.matmul(g3, w4), b4))\n",
    "print(g4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    f = sess.run(g4,feed_dict = {x: a, y: b, w1: nn.W[0], w2: nn.W[1], w3: nn.W[2], w4: nn.W[3],\n",
    "                             b1: nn.B[0], b2: nn.B[1], b3: nn.B[2], b4: nn.B[3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12157428, -0.07123873],\n",
       "       [-0.11776307, -0.07139242],\n",
       "       [-0.13612098, -0.07489069]], dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2,  1],\n",
       "       [ 1,  1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array([[1,2],[2,3]]) - array([[3,1],[1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
